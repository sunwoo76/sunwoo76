# Research Interest
I have mainly researched generative models with multi-modal data for vairous applications with different conditions.  
**Generative Models**. e.g., Diffusion Models, Image-to-Image Translation, Style Transfer etc. <br>
**Multimodal Learning**. e.g., Audio-guided Image Manipulation, Text-guided Image Manipulation, etc. <br>

Meanwhile, I am mainly interested in instructive, interactive, and personalized practical applications by understanding the intention of user actions. Additionally, I am also interested in **Generative models & understanding and learning relations or representations in images and between images and other modalities, visual perception(detection, detection), and their further extensions to the 3D or video applications**.

# Education

* Korea University, Seoul, Korea
  * M.S. Student in Computer Science and Engineering
  * Mar. 2021 - Aug. 2023

* Dongguk University, Seoul, Korea
  * B.S. in Computer Engineering
  * Mar. 2014 - Aug. 2020

# Experience

* Naver AI Research Intern (Naver, Seongnam, Korea)
  * June. 2022 - Nov. 2022
  * Mentor: Gayoung Lee
  
* Undergraduate Intern (Korea University <a href="https://cvlab.korea.ac.kr">CVLAB</a>, Seoul, Korea)
  * Aug. 2020 - Feb. 2021
  * Advisor: Prof. Seungryong Kim

# Publications

## International Journal

> **Controllable Style Transfer via Test-time Training of Implicit Neural Representation**<br>
>> **Sunwoo Kim**\*, Youngjo Min, Younghoon Jeong and Seungryong Kim<br>
>> ArXiv Preprint, 2022.<br>
>> <a href="https://ku-cvlab.github.io/INR-st/">[Project Page]</a> <a href="https://arxiv.org/abs/2210.07762">[arXiv]</a> 

## International Conference

> **DiffMatch: Diffusion Model for Dense Matching**<br>
>> Jisu Nam, Gyuseong Lee, **Sunwoo Kim**, Hyunsu Kim, Hyungwon Cho, Seyeon Kim, Seungryong Kim<br>
>> International Conference on Learning Representations (**ICLR, 1.2\% Oral presentation**), 2024.<br>
>> <a href="https://arxiv.org/abs/2305.19094">[arXiv]</a>

> **User-friendly Image Editing with Minimal Text Input: Leveraging Captioning & Injection Technique**<br>
>> **Sunwoo Kim**\*, Wooseok Jang,  Hyunsu Kim, Junho Kim, Yunjei Cho, Seungryong Kim and Gayoung Lee<br>
>> <a href="https://arxiv.org/abs/2306.02717">[arXiv]</a> 

> **LANIT: LAnguage-Driven Unsupervised Image-to-Image Translation for Unlabeled Data**<br>
>> Jihye Park\*, **Sunwoo Kim**\*, Soohyun Kim\*,  Seokju Cho, Jaejun Yoo, Youngjung Uh and Seungryong Kim<br>
>> Conference on Computer Vision and Pattern Recognition (**CVPR**), 2023.<br>
>> <a href="https://ku-cvlab.github.io/LANIT/">[Project Page]</a> <a href="https://arxiv.org/abs/2208.14889">[arXiv]</a> 

> **Deep Translation Prior: Test-time Training for Photorealistic Style Transfer**<br>
>>  **Sunwoo Kim**\*, Soohyun Kim\* and Seungryong Kim<br>
>> 36th AAAI Conference on Artificial Intelligence, (**AAAI**) 2022.<br>
>> <a href="https://github.com/sunwoo76/Deep_Translation_Prior">[Github]</a> <a href="https://arxiv.org/abs/2112.06150">[arXiv]</a>

# Projects

* Human talking face Generation Projects
  * June. 2022 - Nov. 2022
